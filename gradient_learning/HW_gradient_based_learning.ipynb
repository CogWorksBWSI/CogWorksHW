{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "> Written by Nick Stanisha and Ryan Soklaski\n",
    "\n",
    "Given that \n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{d}{dx}x^n = nx^{n-1}\n",
    "\\end{equation}\n",
    "\n",
    "Write a function, `poly_grad` that computes the derivative of a polynomial of arbitrary degree, evaluated at some specified value for $x$.\n",
    "\n",
    "That is, if we want to compute the derivative of $f(x) = 0\\;x^0 + 2\\;x^1 + 4\\;x^2$, at $x=2$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{df}{dx} = 0 + 2\\;x^0 + 8\\;x^1\\\\\n",
    "\\frac{df}{dx}\\Bigr|_{x=2} = 0 + 2 + 8\\;(2)^1 = 18\n",
    "\\end{equation}\n",
    "\n",
    "Accordingly, your function `poly_grad` should behave as follows:\n",
    "```python\n",
    ">>> poly_grad((0, 2, 4), 2)\n",
    "18\n",
    "```\n",
    "where we specify the polynomial by simply specifying its coefficients in ascending order of power.\n",
    "\n",
    "Because we are working with a single-variable function, we can simply evaluate the derivative rather than a gradient (i.e. `poly_grad` will return a number rather than a vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_grad(coefs, x):\n",
    "    \"\"\" Computes the derivative of a polynomial with coefficients `coefs`, evaluated \n",
    "        at `x`.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        coefs : Tuple[float]\n",
    "            The polynomial coefficients in increasing order (C0, C1, C2, ...)\n",
    "            \n",
    "            This corresponds to the polynomial: C0 + C1*x + C2*(x**2) + ...\n",
    "            \n",
    "            If `coefs` is an empty tuple, then the polynomial is 0.\n",
    "            \n",
    "        x : float\n",
    "            The value at which to evaluate the derivative\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The derivative of the polynomial function at x\n",
    "        \n",
    "        Examples\n",
    "        -------\n",
    "        >>> # Using the polynomial: 0 + 2*x + 4*(x ** 2)\n",
    "        >>> # compute the derivative when x = 2\n",
    "        >>> # i.e. 8*(2) + 2 -> 18\n",
    "        >>> poly_grad([0, 2, 4], 2)\n",
    "        18\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bwsi_grader.cogworks.gradient_learning import grade_polygrad\n",
    "grade_polygrad(poly_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, implement vanilla gradient descent in order *minimize* the polynomial. Refer to the course material from this module for a detailed discussion of gradient descent.\n",
    "\n",
    "This function will not only iteratively update `x` to try to minimize `f(x)`, but it will also keep track of all of the values of `x` during this process. This will allow us to make some nice visualizations of the gradient descent process.\n",
    "\n",
    "A note about your implementation: do not worry about dividing $\\frac{df}{dx}$ by $\\left|\\frac{df}{dx}\\right|$. This is a case where doing so will actually slow down our minimization process. (If you don't know what I'm talking about, revisit the section on gradient descent in the module).\n",
    "\n",
    "After you implement gradient descent and produce the visualization, see if you can envision what the gradient descent trajectory would have looked like if you *had* normalized the step-size, $\\delta$, by $\\left|\\frac{df}{dx}\\right|$ so that each step taken was of an equal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_descent(poly, step_size=0.1, iterations=10, x=100.):\n",
    "    \"\"\" Returns a list of x-values visited when optimizing `poly` through gradient descent \n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        poly : List[float]\n",
    "            Polynomial coefficients in increasing order\n",
    "        step_size : Optional[float], default: 0.1\n",
    "            The magnitude of the step to take for each update of x\n",
    "        iterations : Optional[int], default: 10\n",
    "            After this number of iterations, the grad_descent function should return\n",
    "        x : Optional[float], default: 100.\n",
    "            The initial value of x\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        x_list : list\n",
    "            A list of the values of x that were visited, including\n",
    "            the initial value of x.\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        Pseudo-code for this\n",
    "        - Initialize x_list to contain the initialized value `x`\n",
    "        - Until you've exhausted the total number of iterations\n",
    "          - Compute the gradient (just the derivative) of poly with respect to x\n",
    "          - Update x using stepsize\n",
    "          - Add the new value of x to x_list\n",
    "        - Return x_list\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bwsi_grader.cogworks.gradient_learning import grade_gradient_descent\n",
    "grade_gradient_descent(grad_descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustrating gradient descent to find the minimum of $f(x) = 2x ^2 + 15$. The following cell uses your `grad_descent` function, and plots the \"trajectory\" of 15 steps taken via gradient descent. We use a step-size of $\\delta = 0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell; it will run your `grad_descent` function and will plot \n",
    "# the \"trajectory\" of the x-values visited.\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "x_list = grad_descent([15, 0, 2])\n",
    "colors = ['lightgreen'] + ['lightgray'] * (len(x_list) - 2) + ['r']\n",
    "\n",
    "ax.plot(np.linspace(-100, 100, 1001), 2*(np.linspace(-100, 100, 1001)**2) + 15)\n",
    "ax.plot(x_list, [2*(x**2) + 15 for x in x_list], c='r', ls='--')\n",
    "ax.scatter(x_list, [2*(x**2) + 15 for x in x_list], c=colors, s=100, zorder=1000)\n",
    "ax.text(-75, 20000, 'Start: {:.2f}'.format(x_list[0]), color='green')\n",
    "ax.text(-75, 19200, 'End:   {:.2f}'.format(x_list[-1]), color='red')\n",
    "ax.set_ylabel(r\"$L(x)$\")\n",
    "ax.set_xlabel(r\"$x$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that by making iterative adjustments to the variable $x$, we are able to find the _value of x which minimizes the value of the polynomial_. Take a moment to consider why this is important in a machine learning context. Instead of an arbitrary polynomial, what if this function described _how wrong our current model is_ (i.e. if the polynomial was a **loss function**), and $x$ represented a trainable model parameter. Keep in mind that instead of a single parameter $x$, in reality we will want to optimize over _thousands or millions of parameters_ which describe our model.\n",
    "\n",
    "(Also note that the fact that the minimum lies at $x = 0$ is merely a facet of this simple example. We are finding the value of $x$ that minimizes $f$, whatever it may be.)\n",
    "\n",
    "By making iterative adjustments, exactly like the ones we've just implemented, we could find the _model parameters_ that _minimize our loss function_. Therefore, if our mathematical description of \"error\" accurately reflects what a human would consider to be \"bad\", then we could make our learned model perform better and better as it undergoes training. This, in essence, is what machine learning is -- finding the values of  the parameters of a complex model that minimize the loss function that we derived for some task. By following the gradient to improve those parameters, software can _learn from data_ to get better at performing that task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical Issues for Gradient Descent \n",
    "Recall from your reading that there are three major issues that arise when utilizing gradient descent. \n",
    " 1. It is not clear what step-size should be used when updating your parameters. \n",
    " 2. The gradient descent method can only reveal that you are at the bottom of a valley - it cannot indicate that you are at the bottom of the lowest valley. \n",
    " 3. One must take care, when coming up with a loss function, to ensure that the function is differentiable.\n",
    " \n",
    "We'll demonstrate points 1 and 2 in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we use a step-size of $\\delta=0.4$ to perform gradient descent on the same function. Although we end up near the minimum, we take much larger steps to get there than before. So far, it isn't clear if $\\delta=0.4$ is any better or worse than $\\delta=0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute this cell\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "x_list = grad_descent([15, 0, 2], step_size=0.4)\n",
    "colors = ['lightgreen'] + ['lightgray'] * (len(x_list) - 2) + ['r']\n",
    "\n",
    "ax.plot(np.linspace(-100, 100, 1001), 2*(np.linspace(-100, 100, 1001)**2) + 15)\n",
    "ax.plot(x_list, [2*(x**2) + 15 for x in x_list], c='r', ls='--')\n",
    "ax.scatter(x_list, [2*(x**2) + 15 for x in x_list], c=colors, s=100, zorder=1000)\n",
    "ax.text(-75, 20000, 'Start: {:.2f}'.format(x_list[0]), color='green')\n",
    "ax.text(-75, 19200, 'End:   {:.2f}'.format(x_list[-1]), color='red')\n",
    "ax.set_ylabel(r\"$L(x)$\")\n",
    "ax.set_xlabel(r\"$x$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we perform gradient descent with a step-size of $\\delta = 0.6$, beginning at x=3. Using such a large step size causes us to move *away* from the minimum! It may seem like we started near the minimum, but note the scale of the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "x_list = grad_descent([15, 0, 2], step_size=0.6, x=3) \n",
    "colors = ['lightgreen'] + ['lightgray'] * (len(x_list) - 2) + ['r']\n",
    "\n",
    "ax.plot(np.linspace(-100, 100, 1001), 2*(np.linspace(-100, 100, 1001)**2) + 15)\n",
    "ax.plot(x_list, [2*(x**2) + 15 for x in x_list], c='r', ls='--')\n",
    "ax.scatter(x_list[::-1], [2*(x**2) + 15 for x in x_list][::-1], c=colors[::-1], s=100, zorder=1000)\n",
    "ax.text(-75, 20000, 'Start: {:.2f}'.format(x_list[0]), color='green')\n",
    "ax.text(-75, 19200, 'End:   {:.2f}'.format(x_list[-1]), color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that, depending on your gradient descent implementation, the path to the global minimum is not always smooth and, if you are too aggressive with your `step_size`, you can actually _diverge_ from the minimum, even if you start close to it. Just like $k$ in the $k$-nearest neighbor classifier from your previous assignment, the gradient descent step size is a _hyperparameter_ of your model, which you must set prior to the training process (however, there are variations on gradient descent which adjust the step size automatically while performing the optimization). Cross-validation can be used to arrive at a good step-size (a.k.a. learning rate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-convex functions\n",
    "Notice that $2x^{2} + 15$ is a [convex function](https://en.wikipedia.org/wiki/Convex_function). Convex functions are generally bowl-shaped and have a single, unique global minimum. Although convex functions are useful for learning about optimization, most of the functions that we will be minimizing to train our machine learning models (\"loss functions\") will be non-convex over our model's parameters. A simple example of a non-convex function is shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute this cell to plot gradient descent for a non-convex function\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "x = np.linspace(-1.5, 2, 1001)\n",
    "\n",
    "def f(x):\n",
    "    return 1 + x - (x ** 2) - (x ** 3) + (x ** 4)\n",
    "\n",
    "x_list = grad_descent([1, 1, -1, -1, 1], x=2, step_size=0.03)\n",
    "colors = ['lightgreen'] + ['lightgray'] * (len(x_list) - 2) + ['r']\n",
    "\n",
    "ax.plot(x, f(x))\n",
    "ax.plot(x_list, [f(x) for x in x_list], c='r', ls='--')\n",
    "ax.scatter(x_list, [f(x) for x in x_list], c=colors, s=100, zorder=1000)\n",
    "ax.text(-1, 7, 'Start: {:.2f}'.format(x_list[0]), color='green')\n",
    "ax.text(-1, 6.8, 'End:   {:.2f}'.format(x_list[-1]), color='red')\n",
    "ax.set_ylabel(r\"$L(x)$\")\n",
    "ax.set_xlabel(r\"$x$\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice in this example that the minimum that gradient descent finds, $(1, 1)$, looks good from the perspective of the algorithm. However, what gradient descent is incapable of seeing is that a better solution lies just beyond the hill that peaks around $x = 0.4$.\n",
    "\n",
    "Can you think of any good ways to help rattle your model out of this non-optimal minimum? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "Now that we have learned about gradient descent, it is time to use it to create our first \"intelligent\" software. Imagine that you work for a company that produces films and you've been tasked with forecasting how well a movie is going to perform once it is released. Instead of using your own intuition, you could train a model using historical data, and use it to predict how a new movie is going to do. Let's say that you have the following data (all measured in millions of dollars):\n",
    "\n",
    "* The first year box office sales\n",
    "* The amount of money spent producing the movie\n",
    "* The amount of money spent promoting the movie\n",
    "* The total book sales (you can assume all of your movies are based on books)\n",
    "\n",
    "Using this data, how can we predict how well a movie is going to do (box office sales)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Box Office Sales': [85.1, 106.3, 50.2, 130.6, 54.8, 30.3, 79.4, 91.0, 135.4, 89.3],\n",
    "    'Production Costs': [8.5, 12.9, 5.2, 10.7, 3.1, 3.5, 9.2, 9.0, 15.1, 10.2],\n",
    "    'Promotion Costs': [5.1, 5.8, 2.1, 8.4, 2.9, 1.2, 3.7, 7.6, 7.7, 4.5],\n",
    "    'Book Sales': [4.7, 8.8, 15.1, 12.2, 10.6, 3.5, 9.7, 5.9, 20.8, 7.9]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by plotting box office sales against the other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "for var, ax in zip(['Production Costs', 'Promotion Costs', 'Book Sales'], axes):\n",
    "    ax.scatter(data[var], data['Box Office Sales'])\n",
    "    ax.set_xlabel(var + ' (millions)')\n",
    "    ax.grid(True)\n",
    "    if var == 'Production Costs':\n",
    "        ax.set_ylabel('Box Office Sales (millions)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the looks of things, it seems like production and promotion costs are strongly correlated with box office success (this should match up with your intution: a big-budget movie like \"The Avengers\" will normally sell more tickets than smaller, independent films).\n",
    "\n",
    "Let's try to use *supervised learning* to train a model to make predictions. We will need to:\n",
    " 1. Devise a model that is capable of taking input data regarding a movie, and using its parameters to map this to a prediction of the movie's earnings.\n",
    " 2. Create a (differentiable) loss function that measures how well the model's prediction compares to \"truth data\" (i.e. actual Box Office numbers)\n",
    " 3. Refine the model's parameters by using gradient descent to find the model parameter values that minimize the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "You have primarily enountered *classification problems* up to this point. For example, your $k$-means clustering model classified images based on whether they contained dogs, trucks, etc. This entails predicting a discrete value (i.e. a label).\n",
    "\n",
    "Here we will use supervised learning (we are learning from labels) to train a model to predict a *continuous quantity* rather than a discrete category. This type of analysis is called _regression_ and it has many applications in statistics, data science, medicine, marketing, and other domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "Remember our general approach for machine learning: \n",
    "- Construct a model that is able to take input data and make a prediction using that data and parameters stored within the model.\n",
    "- Summarize the performance of our model's prediction with a \"loss function\": a bad prediction should produce a higher loss-value than a good prediction.\n",
    "- Make our model's performance less-bad through iterative improvements to its parameters, such that the loss function is being minimized; that is, perform gradient descent to adjust the model's parameters in an effort to find values that minimize the loss function \n",
    "\n",
    "We will introduce use the model parameters $A_{bias}, A_{prod}, A_{prom}, A_{book}$, to map our input data, $X$ (which represents the production costs, promotion costs, and book sales) to the predicted box office earnings, $\\hat{y}$, via some function $f$. \n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y} = f(X; A_{bias}, A_{prod}, A_{bias}, A_{book})\n",
    "\\end{equation}\n",
    "\n",
    "Our model's prediction mechanism is represented by this function $f(X; A_{bias},  A_{prod}, A_{prom}, A_{book}, )$. Note that we use a semicolon to simply separate the input-data variable from the model parameters.\n",
    "\n",
    "\n",
    "$A_{prod}$, $A_{prom}$, and $A_{book}$ will affect how heavily the prediction costs, promotion costs, and book sales should be weighed, when predicting the box office earnings. $A_{bias}$ allows the model to make gross shifts to the predicted value. \n",
    "\n",
    "Then, we must score how good our model's prediction is with a loss function, $g$, which must compare our predicted output, $\\hat{y}$, against the expected output, $y$.\n",
    "\n",
    "\\begin{equation}\n",
    "L = g(y, \\hat{y})\n",
    "\\end{equation}\n",
    "\n",
    "Using gradient descent on $L$ with respect to our parameters $A_{bias},  A_{prod}, A_{prom}, A_{book}$, we will _learn parameters values for our model that minimize the error of the model's predictions_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "For each of the $N$ movies in our dataset, our model will produce an estimate of the box office sales. One common choice for a loss function is the average squared error over all the data.\n",
    "\n",
    "\\begin{equation}\n",
    "L = \\frac{1}{N}\\sum_{i = 1}^{N} (y_i - \\hat{y}_{i})^2\n",
    "\\end{equation}\n",
    "\n",
    "$y_i$ is the true Box Office earning for movie $i$, and $\\hat{y}_{i}$ is our model's predicted earning for that movie. \n",
    "\n",
    "Our loss takes the difference between the predicted earning and the historical Box Office earning, squares it, and computes the average of this squared difference for all of the movies in our training data. \n",
    "\n",
    "Notice that this function penalizes $\\hat{y}$ equally regardless of whether the predicted income is larger or smaller than the true earning. Also, if our predictions are perfect, the loss drops to 0. Lastly, note that our loss function is *differentiable*, which is necessary in order to perform gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Model\n",
    "Now we need to arrive at the functional form for our model, $f$. There appears to be roughly a linear correlation between the three different pieces of input data (promotion costs, production costs, and book earnings) and the Box Office earnings. Thus we will design our model to perform a *linear mapping* from the input data to the predicted earning.\n",
    "\n",
    "For each movie, we have the financial data $X = [X_{prod}, X_{prom}, X_{book}]$. A simple way to predict box office sales from this data is to construct a weighted sum of these features using our parameters\n",
    "\n",
    "\\begin{equation}\n",
    "f(X; A_{bias},  A_{prod}, A_{prom}, A_{book}, ) = A_{bias} + (X_{prod} \\times A_{prod}) + (X_{prom} \\times A_{prom}) + (X_{book} \\times A_{book})\n",
    "\\end{equation}\n",
    "\n",
    "Since our model is _linear_ with respect to our data, $X$, we are performing [linear regression](https://en.wikipedia.org/wiki/Linear_regression). \n",
    "\n",
    "Expressing $\\vec{X}$ as the vector $[1, X_{prod}, X_{prom}, X_{book}]$ and $\\vec{A}$ as $[A_{bias}, A_{prod}, A_{prom}, A_{book}]$, we can equivalently express $f$ using the dot-product: \n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y} = f(\\vec{X}; \\vec{A}) = \\vec{A} \\cdotp \\vec{X}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\cdot$ is the standard [dot product](https://en.wikipedia.org/wiki/Dot_product)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias\n",
    "\n",
    "The $A_{bias}$ term is essentially the same as the $b$ term in $y = mx + b$. In our context, it extrapolates the estimated box office sales when the promotion cost, production cost and book sales are all $0. In general, you should not expect the bias term to equal 0. Imagine, for example, you were attempting to predict the average surface temperature on Earth as a function of greenhouse gas emissions. With 0 emissions, you would not expect the average temperature of the Earth to be 0 degrees Kelvin.\n",
    "\n",
    "### Putting it All Together\n",
    "\n",
    "\\begin{equation}\n",
    "L = \\frac{1}{N}\\sum_{i = 1}^{N} (y_i - \\vec{A} \\cdotp \\vec{X}_{i})^2\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla L = -\\frac{2}{N}\\sum_{i = 1}^{N} (y_i - \\vec{A} \\cdotp \\vec{X}_{i}) \\vec{X}_{i}\n",
    "\\end{equation}\n",
    "\n",
    "The sum runs over all $N$ movies in our training data. $\\vec{X}_{i}$ stores the input financial data, as detailed above, for movie $i$. Notice that $(y_i - \\vec{A} \\cdotp \\vec{X}_{i})$ is a *scalar* being multiplied with the *vector* $\\vec{X}_{i}$.\n",
    "\n",
    "Here, the **gradient**, $\\nabla L$, is the vector:\n",
    "\n",
    "\\begin{equation}\n",
    "[\\frac{\\partial L}{\\partial A_{bias}}, \\frac{\\partial L}{\\partial A_{prod}}, \\frac{\\partial L}{\\partial A_{prom}}, \\frac{\\partial L}{\\partial A_{book}}]\n",
    "\\end{equation}\n",
    "\n",
    "As an exercise, derive the vector-form equation that we provided for the gradient. That is, write the loss out in long-form:\n",
    "\\begin{equation}\n",
    "L = \\frac{1}{N}\\sum_{i = 1}^{N} (y_i - A_{bias} - X_{prod} A_{prod} - X_{prom} A_{prom} - X_{book} A_{book})^2\n",
    "\\end{equation}\n",
    "\n",
    "And compute all four partial derivatives, $\\frac{\\partial L}{\\partial A}$. Assemble the gradient $[\\frac{\\partial L}{\\partial A_{bias}}, \\frac{\\partial L}{\\partial A_{prod}}, \\frac{\\partial L}{\\partial A_{prom}}, \\frac{\\partial L}{\\partial A_{book}}]$ and verify that this is the same as the vector-form $-\\frac{2}{N}\\sum_{i = 1}^{N} (y_i - \\vec{A} \\cdotp \\vec{X}_{i}) \\vec{X}_{i}$\n",
    "\n",
    "Objective: Find the model parameters $\\vec{A}$ that minimize $L$, given the provided data $\\vec{X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_and_gradient(X, A, y):\n",
    "    \"\"\" Given the input data (X), the collection of model parameters (A), and the \n",
    "        truth data (y). Compute the loss, and the gradient of the loss (evaluated at A).\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.ndarray (shape = (N, 4))\n",
    "            The data for all movies, with the first column of the array \n",
    "            always equal to 1\n",
    "        A : np.ndarray (shape = (4,))\n",
    "            The model parameters: A_bias, A_prod, A_prom, A_book\n",
    "        y : np.ndarray (shape = (N,))\n",
    "            The true box office sales for each movie\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out : tuple\n",
    "            The first entry is the calculated loss and the second entry is the gradient \n",
    "            evaluated at A.\n",
    "            \n",
    "            The loss should be a single floating-point number\n",
    "            The gradient should be a numpy array of shape-(4,)\n",
    "        \n",
    "        Fun challenge (optional): For both the loss and the gradient try using matrix \n",
    "        multiplication and broadcasting to avoid using any for-loops.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bwsi_grader.cogworks.gradient_learning import grade_loss_and_gradient\n",
    "grade_loss_and_gradient(loss_and_gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will initialize our model parameters with random values, sampled from a Gaussian distribution centered at 0, and with a standard deviation of 1. We will train our model on the financial data that was plotted above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Box Office Sales': [85.1, 106.3, 50.2, 130.6, 54.8, 30.3, 79.4, 91.0, 135.4, 89.3],\n",
    "    'Production Costs': [8.5, 12.9, 5.2, 10.7, 3.1, 3.5, 9.2, 9.0, 15.1, 10.2],\n",
    "    'Promotion Costs': [5.1, 5.8, 2.1, 8.4, 2.9, 1.2, 3.7, 7.6, 7.7, 4.5],\n",
    "    'Book Sales': [4.7, 8.8, 15.1, 12.2, 10.6, 3.5, 9.7, 5.9, 20.8, 7.9]\n",
    "}\n",
    "\n",
    "# We initialize the four model parameters as random numbers distributed near 0.\n",
    "N = len(data['Box Office Sales'])\n",
    "y = np.array(data['Box Office Sales'])\n",
    "X = np.vstack([np.ones(N), data['Production Costs'], data['Promotion Costs'], data['Book Sales']]).T\n",
    "A = np.random.normal(size=(4,)) # the four model parameters\n",
    "\n",
    "# will store the loss values recorded during training\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a step size of $0.001$, train your model for 400 iterations. That is, given the data `X`, model parameters `A`, and historical box-office sales `y`, compute the loss and the gradient. Append the loss value to the list `losses` and update the model's parameters using gradient descent. Repeat this for a total of 400 \"training steps\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT CODE GOES HERE\n",
    "step_size = 0.001\n",
    "iterations = 400\n",
    "losses = list()\n",
    "\n",
    "for _ in range(iterations):\n",
    "    loss, grad = loss_and_gradient(X, A, y)\n",
    "    A -= step_size * grad\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute this cell to plot your loss as it changed during training\n",
    "# note that the y-axis is plotted on a log-scale\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "\n",
    "ax.plot(losses)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xlabel(\"Training Step\");\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell to visualize what weighting your model learned\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "ax.barh(np.arange(3), A[1:])\n",
    "ax.set_yticks([0, 1, 2])\n",
    "ax.set_yticklabels(['Production Costs', 'Promotion Costs', 'Book Sales'])\n",
    "ax.set_xlabel(\"Learned Weights\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model seems to have learned that the amount of money spent on promoting the movie has the highest effect on total box office success. Using [regression analysis](https://en.wikipedia.org/wiki/Regression_analysis) it is possible to determine confidence intervals for these weights, but that is beyond the scope of this course.\n",
    "\n",
    "Let's perform a regression only using the promotional costs data and visualize our results. The red line will indicate the (linear) prediction made by our trained model, and the blue dots show the true box-office earnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prom = X[:, (0, 2)]\n",
    "A_prom = np.random.normal(size=(2,))\n",
    "\n",
    "step_size = 0.001\n",
    "iterations = 400\n",
    "\n",
    "##STUDENT CODE GOES HERE##\n",
    "# perform the same training as before, but\n",
    "# use `X_prom` and `A_prom` as the data and model weights\n",
    "step_size = 0.001\n",
    "iterations = 400\n",
    "\n",
    "for _ in range(iterations):\n",
    "    loss, grad = loss_and_gradient(X_prom, A_prom, y)\n",
    "    A_prom -= step_size * grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute this cell to visualize the linear model that was\n",
    "# learned to map promotional costs to predicted box office sales\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "ax.scatter(data['Promotion Costs'], data['Box Office Sales'])\n",
    "x_dat = np.array([min(data['Promotion Costs']), max(data['Promotion Costs'])])\n",
    "y_dat = [A_prom[0] + A_prom[1] * x for x in x_dat]\n",
    "ax.plot(x_dat, y_dat, c='r')\n",
    "ax.set_xlabel(\"Promotional Costs (millions)\")\n",
    "ax.set_ylabel(\"Box Office Sales (millions)\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusions\n",
    "To summarize, we have just used gradient-based optimization to \"teach\" a model the dependency between some data (expenses and book sales) and a quantity that we care about (the total box office sales). Although this model might not be able to play chess, converse with a human, or drive a car, it _is_ using machine learning at its core. In fact, if you revisit the \"Perspective on Machine Learning\" module, you'll see that all of those applications use the same approach for a wide variety of applications, many of which have inspired lucrative businesses and profound technical breakthroughs.\n",
    "\n",
    "By completing this assignment, you have been introduced to\n",
    "\n",
    "* Gradient descent and optimization\n",
    "* Linear regression, a powerful and widely-applied technique in machine learning\n",
    "* Data-driven applications (knowing nothing at the start and _learning_ dependencies that are present in your data)\n",
    "\n",
    "In the next machine learning unit we'll cover\n",
    "\n",
    "* Optimization for differentiable composite functions\n",
    "* Some other machine learning algorithms (logistic regression, SVMs)\n",
    "* Deep learning with neural networks"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
