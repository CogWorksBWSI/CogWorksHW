{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbor Classifier\n",
    "> Adapted from the CS231n coursework, by Nick Stanisha and Ryan Soklaski\n",
    "\n",
    "In this notebook, we will step through the process of training a \"nearest neighbor\" classifier, using the CIFAR-10 dataset. CIFAR-10 is an academic dataset consisting of 60,000 32x32 RGB images. Each image belongs to one of ten different classes: \n",
    "\n",
    " - airplane, class-id: 0\n",
    " - automobile, class-id: 1\n",
    " - bird, class-id: 2\n",
    " - cat, class-id: 3\n",
    " - deer, class-id: 4\n",
    " - dog, class-id: 5\n",
    " - frog, class-id: 6\n",
    " - horse, class-id: 7\n",
    " - ship, class-id: 8\n",
    " - truck, class-id: 9\n",
    "\n",
    "10,000 of those images are \"held out\" as a test set, which is reserved for testing the quality of your classifier after your training process is complete.\n",
    "\n",
    "Our goal here is to classify an unseen image based on its \"proximity\" to other, labeled images. Thus, we are assuming that two images are similar if their corresponding pixels have similar RGB values to one another. As described in the reading, we can utilize L2-distance to measure the proximity of images relative to one another.\n",
    "\n",
    "Suppose an unlabeled image has a bunch of dark blue pixels along its bottom-half (water), a bunch of light-blue pixels along its top-half (sky), and a large white blob in the the middle. Then that image will likely have a small L2-distance with our labeled images containing ships, since those images will likely have a similar arrangement of pixel colors, more so than would a picture of a truck. If the image is indeed closer in proximity to labeled images of ships than it is to other classes of images, then our classifier will label the image as \"ship\" (i.e. assign it class-id 8).\n",
    "\n",
    "More precisely, given our unlabeled image, we will consult its k-nearest neighbors (the k labeled images that have the smallest L2-distance with it). The most common label among those k labeled images will be used to classify the unlabeled images. Here, k is a positive integer that we select upfront. We will discuss what to do if there is a tie among the k labels later on in the notebook.  \n",
    "\n",
    "So if k = 10, we will find the 10 labeled images the have the smallest L2 distance with our unlabeled image. Suppose that among those labeled images are 1 car, 3 birds, and 6 ships, then we will classify the unlabeled image as a ship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell!\n",
    "%matplotlib notebook\n",
    "import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the data\n",
    "Let's start by downloading and loading the cifar10's images and labels as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads the cifar10 dataset (unless the file\n",
    "# already exists). This requires internet connectivity \n",
    "# and may take a couple of minutes to complete\n",
    "if not cifar10.get_path().is_file():\n",
    "    cifar10.download()\n",
    "else:\n",
    "    print(\"cifar10 is already downloaded at:\\n{}\".format(cifar10.get_path()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cifar-10 images are saved as arrays of unsigned 8-bit numbers. We want to do arithmetic associated with non-integer values (i.e. taking the square root in the L2-distance), thus we will convert these arrays to store 32-bit floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = (i.astype(\"float32\") for i in cifar10.load())\n",
    "x_train = x_train.transpose([0,2,3,1])\n",
    "x_test = x_test.transpose([0,2,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training data shape: ', x_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', x_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('\\n')\n",
    "print('data type: {}'.format(x_train.dtype))\n",
    "print('label type: {}'.format(y_train.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data is a 4D array with a shape of (50000, 32, 32, 3), corresponding to 50,000 images, each image comprised of a 32x32 array of RGB-values.\n",
    "\n",
    "The training labels are a 1D array of the class-ID for each image. The class-IDs are integers 0-9, and are listed in correspondence with their associated word-labels above\n",
    "\n",
    "Let's look at the first training image and its class-ID, and see that the label matches the content of the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the image is represented by a 32x32x3 array\n",
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing the class-label for image-0\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class-ID of the first training image is 6. Referring back to the list at the beginning of the notebook, we see that this image contains a frog. Let's see that this is the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(x_train[0].astype(\"uint8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a frog! We are getting a handle on how the training data and labels correspond to each other. Now, let's plot a grid of images from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some examples from the dataset.\n",
    "# We show a few examples of training images from each class.\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "fig, axes = plt.subplots(nrows=samples_per_class, ncols=num_classes)\n",
    "\n",
    "for label_ind, cls in enumerate(classes):\n",
    "    idxs = np.where(y_train == label_ind)[0]\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        axes[i, label_ind].imshow(x_train[idx].astype('uint8'))\n",
    "        axes[i, label_ind].xaxis.set_major_locator(plt.NullLocator())\n",
    "        axes[i, label_ind].yaxis.set_major_locator(plt.NullLocator())\n",
    "        if i == 0:\n",
    "            axes[i, label_ind].set_title(cls)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50,000 images is a good amount of data. For the sake of expediency, we will only use the first 5000 training images and 500 test images, respectively. If your computations are taking a long time, be sure to check that you executed this cell, and that you are indeed operating on this subset of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x_train[:5000], y_train[:5000]\n",
    "x_test, y_test = x_test[:500], y_test[:500]\n",
    "print('Training data shape: ', x_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', x_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the L2-distance between two images, we will want to flatten them out so that all of the RGB values of all their pixels of an image is in a 1-dimensional array. Thus each image will be a 3072-length 1D array (32x32x3 = 3072). Let's reshape our train/test data arrays to \"flatten\" each image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape-(5000, 32, 32, 3) -> shape-(5000, 3072)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], -1))\n",
    "\n",
    "# shape-(500, 32, 32, 3) -> shape-(500, 3072)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], -1))\n",
    "print(\"new train-shape:\", x_train.shape)\n",
    "print(\"new test-shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Classifier\n",
    "\n",
    "## Question 1\n",
    "Now we must implement the code that will compute the distance of $M$ unlabeled images with *each* of our $N$ labeled images, producing an MxN array of L2-distances.\n",
    "\n",
    "Your output should have the following properties\n",
    "* `dists` is a `np.array` with shape `(M, N)`\n",
    "* `dists[i, j]` = the L2 distance between `x_unlabeled[i]` and `x_train[j]`\n",
    "* `compute_distances` should _not_ use two explicit loops to calculate all pairs of L2-distances between the M unlabeled images and the N labeled training images. This will be prohibitively slow. Instead, use broadcasting to perform this computation in a fully-vectorized way. Refer to the [section on array broadcasting in Python Like You Mean It](https://rsokl.github.io/Learning_Python/Module3_IntroducingNumpy/Broadcasting.html) for details about this calculation.\n",
    "* `compute_distances` should work for arbitrary `x_train` and `x_unlabeled`, as long as they have the same number of columns (i.e. you should _not_ explicitly require 3072 columns in your implementation)\n",
    "\n",
    "** Use the output of the cell below to answer question 1 of the homework **\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> import numpy as np\n",
    ">>> x = np.array([[1., -3., 8., 5.],  # shape-(2, 4)\n",
    "...               [10., 3., 12., 0.]])\n",
    "\n",
    ">>> y = np.array([[1., -3., 8., 5.],  # shape-(3, 4)\n",
    "...               [9.,  0., 5., 2.],\n",
    "...               [22., -1., -12., 0.]])\n",
    "\n",
    "\n",
    ">>> compute_distances(x, y)  # returns shape-(2, 3) array\n",
    "array([[ 0.        ,  9.53939201, 29.49576241],\n",
    "       [12.56980509,  7.93725393, 27.12931993]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute this cell after you have completed this function\n",
    "\n",
    "def compute_distances(x, y):\n",
    "    \"\"\" Write a function that computes the L2 distance between each row \n",
    "        in `x` and `y`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : numpy.ndarray\n",
    "            x.shape must be (M, D)\n",
    "            Each row of `x` is a flattened vector representing the pixel \n",
    "            values of a single image. Thus `x` represents\n",
    "            M images, each one described by a length-D vector.\n",
    "\n",
    "        y : numpy.ndarray\n",
    "            y.shape must be (N, D)\n",
    "            Each row of `y` is a flattened vector representing the pixel \n",
    "            values of a single image. Thus `y` represents\n",
    "            N images, each one described by a length-D vector.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        distances : numpy.ndarray\n",
    "            distances.shape = (M, N)\n",
    "            distances[i, j] = the L2 distance between x[i] and y[j]\n",
    "    \"\"\"\n",
    "    # student code goes here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bwsi_grader.cogworks.nearest_neighbors import grade_distances\n",
    "grade_distances(compute_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "Let's use compute the distances between the images in `x_test` and `x_train`, and examine the resulting shape-(500, 5000) array.\n",
    "\n",
    "** Use the output of the cells below to answer question 2 of the homework **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute this cell\n",
    "\n",
    "dists = compute_distances(x_test, x_train)\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(dists, interpolation='none', cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "Complete the code for the function `predict`, which, given the array of $M \\times N$ distances, the labels, and k, predicts the M labels for the unlabeled images, based off of the labels of its k-nearest neighbors.\n",
    "\n",
    "Suppose k=5. Given an unlabeled image, we want to identify the 5 labeled images that are nearest to it (based on L2-distance), and consult their labels (specifically their class-IDs for cifar10). The most common label will be selected as the label used to classify the unlabeled image. For example, suppose the labels for the 5 nearest neighbors are: 2, 0, 2, 2, 8. Then the predicted label for this unlabeled image will be 2. \n",
    "\n",
    "**If there is a tie among the k labels, the _lowest-value_ class-ID among the tied labels should be used.**\n",
    "\n",
    "## Strategies\n",
    "Test your approach on smaller data\n",
    " - Create your own N labeled images and M unlabeled images, and make up labels for the N images. Use small numbers, like M = 2, N = 5, D = 3, k=3\n",
    " - Compute the $M \\times N$ distances and then, by hand, determine the labels among the k-nearest neighbors for each of the M images. And then label the M images accordingly. Does your code produce the same result?\n",
    " \n",
    "The function [numpy.argsort](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html) will be useful. Also the `collections.Counter` object will likely come in handy here. \n",
    "\n",
    "### Examples\n",
    "Given the distances of one unlabeled images with seven labeled images, we'll predict the label of the image based on `k=5` nearest neighbors\n",
    "\n",
    "```python\n",
    ">>> dists = np.array([[1., 0.1, 3., 2., 10., 1.5, 12.]])  # shape-(1, 7)\n",
    ">>> labels = np.array([2,    0,  2,  2,  3,    8,  5])    # shape-(7,)\n",
    ">>> predict(dists, labels, k=5)\n",
    "array([2])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dists, labels, k=1):\n",
    "    \"\"\" Given a shape-(M, N) array of distances between M-unlabeled \n",
    "        and N-labeled images, and N labels, predict a label for each \n",
    "        of the M images based on its k-nearest neighbors.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dists : numpy.ndarray\n",
    "            `dists.shape` must be (M, N) where M is the number of\n",
    "            examples you wish to predict labels for, and N is \n",
    "            the number of labeled images used in the prediction\n",
    "        \n",
    "        labels : numpy.ndarray\n",
    "            A shape-(N,) array of class-IDs, of labels for the N images.    \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : numpy.array`\n",
    "            A shape-(M,) array of class-IDs, as predicted by the k-nearest\n",
    "            neighbors.\n",
    "    \"\"\"\n",
    "    # student code goes here\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bwsi_grader.cogworks.nearest_neighbors import grade_predict\n",
    "grade_predict(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-nearest-neighbor classifier is a fairly intuitive algorithm. Given a set of training data, to make a prediction on a new point we simply find the k nearest points (measured by L2-distance) and take the most common label among those. \n",
    "\n",
    "Unfortunately, the dimensionality of the CIFAR-10 data is too large (3072 dimensions!) to visualize classification process.\n",
    "\n",
    "To remedy this lack of visualization capability, we'll create a simple dataset with 2D points . This will by our \"toy dataset\". Training points will be manually defined, with each point having a label. Each label will have a distinct color color. The test points will be sampled from the space -1 < x < 1 and -1  < y < 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data points of shape (4, 2)\n",
    "toy_x_train = np.array([[0.7, -0.7],\n",
    "                       [-0.7, -0.7],\n",
    "                       [0, 0.7],\n",
    "                       [0, 0]\n",
    "                      ])\n",
    "# create class-labels of shape (4,)\n",
    "toy_y_train = np.array([0, 1, 2, 3])\n",
    "\n",
    "# define class colors \n",
    "toy_label_colors = {0: 'b',  # class 0 is blue\n",
    "                    1: 'y',  # class 1 is yellow \n",
    "                    2: 'g',  # class 2 is green\n",
    "                    3: 'r'}  # class 3 is is red\n",
    "\n",
    "# Create a set of densly sampled points in the range [-1, 1]\n",
    "xv, yv = np.meshgrid(np.linspace(-1, 1, 100), np.linspace(-1, 1, 100))\n",
    "toy_x_test = np.stack((xv, yv), axis=-1).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of plotting, we'll define a function to plot our 2D data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "def plot_2d_data(x_train, y_train, x_test, test_predictions=np.empty(0)):\n",
    "    \"\"\" Plot data color coded by class.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train : numpy.ndarray\n",
    "        Training data of shape (N, 2).\n",
    "    \n",
    "    y_train : numpy.ndarray\n",
    "        Training labels of shape (N,).\n",
    "    \n",
    "    x_test : numpy.ndarray\n",
    "        Test data of shape (M, 2).\n",
    "    \n",
    "    test_predictions : numpy.ndarray, optional (default=np.array([]))\n",
    "        Test predictions. If no argument is given the points \n",
    "        `x_test` are given the default color code.\n",
    "    \"\"\"\n",
    "    # if no test predictions are given, use the default color\n",
    "    # otherwise, find the corresponding class color\n",
    "    if len(test_predictions) == 0:\n",
    "        test_pt_colors = 'C0'\n",
    "    else:\n",
    "        test_pt_colors = [toy_label_colors[l] for l in test_predictions]\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(*x_test.T, c=test_pt_colors, alpha=0.1)\n",
    "    ax.scatter(*x_train.T, c=[toy_label_colors[l] for l in y_train])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "plot_2d_data(toy_x_train, toy_y_train, toy_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll apply the nearest neighbor classifier our toy dataset. The resulting color coded regions will display the **decision boundaries** found by the classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "dists = compute_distances(toy_x_test, toy_x_train)\n",
    "predictions = predict(dists, toy_y_train)\n",
    "plot_2d_data(toy_x_train, toy_y_train, toy_x_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision boundaries produced by the classifier should have a nice geometric interpretation: this type of equal-area partitioning is known as a \"_Voronoi Tessellation_\".\n",
    "\n",
    "Unfortunately, data encountered in the real world is not as simple as the data generated above. Let's introduce complexity by adding noise around the original points. This will be achieved by perturbing each truth point in the toy dataset with random values sampled from a Gaussian distribution. Each truth point from above will be augmented with several noise samples, the result will be a set of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "def generate_noisy_clusters(x, y, std=0.2, n_cluster_points=100):\n",
    "    \"\"\" Generate clusters around data points by adding random noise.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy.ndarray\n",
    "        Data points of shape (N, 2).\n",
    "        \n",
    "    y : numpy.ndarray\n",
    "        Labels of data points `x` of shape (N,).\n",
    "        \n",
    "    std : float\n",
    "        Standard deviation of noise used to generate clusters.\n",
    "        \n",
    "    n_cluster_points : int, optional (default=100)\n",
    "        Number of data points to generate around each point in `x`.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[numpy.ndarray, numpy.ndarray]\n",
    "        Arrays of shapes (`n_cluster_points`*N, 2) and (`n_cluster_points`*N,)\n",
    "        Containing the data clusters and their labels.\n",
    "    \"\"\"\n",
    "    toy_clusters_x = (np.repeat(x, n_cluster_points, axis=0) \\\n",
    "                      + std * np.random.randn(n_cluster_points*x.shape[0], 2)).clip(-1, 1)\n",
    "    toy_clusters_y = np.repeat(y, n_cluster_points, axis=0)\n",
    "    \n",
    "    return toy_clusters_x, toy_clusters_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "n_cluster_points = 100\n",
    "moise_std = 0.2  # standard deviation of perturbations \n",
    "toy_clusters_x, toy_clusters_y = generate_noisy_clusters(toy_x_train, toy_y_train, moise_std, \n",
    "                                                         n_cluster_points)\n",
    "# run this cell\n",
    "plot_2d_data(toy_clusters_x, toy_clusters_y, toy_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "dists = compute_distances(toy_x_test, toy_clusters_x)\n",
    "predictions = predict(dists, toy_clusters_y)\n",
    "plot_2d_data(toy_clusters_x, toy_clusters_y, toy_x_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the results look compared to before the noise was added?  What happens when you change the standard deviation of the perturbations (experiment with this by changing the ``noise_std`` variable defined a few cells above)? \n",
    "\n",
    "You may have noticed that when we only use the single nearest neighbor outliers can easily cause incorrect classifications, leaving our classifier vulnerable to noise in the data. In the next section we'll look at a method to mitigate this problem.\n",
    "\n",
    "But before we move on, let's inspect some results of the nearest neighbor classifier on a few images from CIFAR-10. \n",
    "\n",
    "We can't visualize the decision boundaries as we did above. Instead, we'll inspect the distances between test images and training images. By doing this, we can get a sense of what \"proximity\" looks like between images.\n",
    "\n",
    "We'll create a small test set of one image and a training set of 10 images. The reduced size of the dataset will allow us observe L2-distances between images using the ``compute_distances`` and ``predict`` functions written earlier. We can determine what image in the training set is \"closest\" to the test image and thus what the classifier will predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_train_set_idxs = range(11)\n",
    "x_train_mini = x_train[mini_train_set_idxs]\n",
    "y_train_mini = y_train[mini_train_set_idxs]\n",
    "\n",
    "mini_test_set_idx = [11]\n",
    "x_test_mini = x_train[mini_test_set_idx]\n",
    "y_test_mini = y_train[mini_test_set_idx]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(x_test_mini.reshape(32, 32,  3).astype(\"uint8\"))  # we flattened the images earlier \n",
    "ax.set_title(f'class: {classes[int(y_test_mini)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = compute_distances(x_train_mini, x_test_mini) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=len(dists), figsize=(8, 3))\n",
    "\n",
    "fig.suptitle(f'Class and L2 distance to test image')\n",
    "for label_ind, dist in enumerate(dists[:, 0]):\n",
    "    axes[label_ind].imshow(x_train_mini[label_ind].astype('uint8').reshape(32, 32, 3))\n",
    "    axes[label_ind].axis('off')\n",
    "    axes[label_ind].set_title(f'{classes[int(y_train_mini[label_ind])]}\\n{dist:1.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the above results, what class would be predicted for the test image (that's really a horse)? What in the images seem to make them \"similar\" to that test image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivating K-Nearest Neighbors\n",
    "\n",
    "We've seen that the nearest neighbor algorithm is susceptible to outliers in our data, this was most tangibly observed on the toy dataset when we added noise. Let's see what happens when, instead of looking at only the first nearest neighbor, we consult the k nearest neighbors.\n",
    "\n",
    "We'll begin by setting k=5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = compute_distances(toy_x_test, toy_clusters_x)\n",
    "predictions = predict(dists, toy_clusters_y, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_data(toy_clusters_x, toy_clusters_y, toy_x_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the results of the KNN classifier compare to the results obtained from using just one neighbor when K=5, 15, 25? Is there a point when increasing K no longer becomes helpful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing Hyperparameters\n",
    "\n",
    "In this nearest-neighbor classification scheme, $k$, is a parameter that we must select prior to predicting labels for our unlabeled data. $k$ is never adjusted or optimized numerically by the classifier itself, thus it is distinguished as a \"hyperparameter\" of the classifier.\n",
    "\n",
    "That being said, we still want to find a value for $k$, such that our classifier provides the most reliable labels for data that we have yet to encounter. Recall that `y_test` represents this \"unseen\" data. Any experimentation that we do to find a good value of $k$ should **not** involve any data from `y_test`. Once we settle on a final value for $k$, we can then measure the final accuracy of our classifier on this \"new\" data, to measure its generalized performance.\n",
    "\n",
    "The process for finding a good value for $k$, then, will have to involve only data and labels from our designated training set. Here we will make use of a strategy known as \"cross-validation\", for identifying good hyperparameter values, without relying on your test data. \n",
    "\n",
    "In cross validation, the training data is separated into $n$ equal-sized segments, which are known as \"folds\". To evaluate the accuracy of our classifier, for a given value of $k$, we use the following process: \n",
    "- Hold out one fold as the unlabeled data, and use the remaining $n-1$ folds as the labeled data. The held-out fold is called the \"validation fold\"\n",
    "- Record the accuracy of the classifier by seeing how well the predicted-labels for the validation fold match their actual labels.\n",
    "- Repeat this process a total of $n$ times, such that each fold is used as a validation fold.\n",
    "\n",
    "By the end of this process, $n$ classifier-accuracies will be recorded, given that value of $k$ (1 one for each validation fold). We can use this to compute the average accuracy for that k-nearest neighbor classifier.\n",
    "\n",
    "We can thus use cross-validation to evaluate our nearest neighbor classifier's accuracy for a variety of values of $k$. The best-performing $k$ will be used when we want to classify data that we genuinely do not have labels for. \n",
    "\n",
    "In the following cells, you will provide code that:\n",
    "- splits the training data and labels into folds for cross validation\n",
    "- for a given value of k, records the classifier accuracies for all n validation folds\n",
    "\n",
    "You will likely want to make use of the numpy functions \"vstack\" and \"concatenate\" to form the data and labels for the train-folds when each validation-fold is held out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Making 'folds' of data\n",
    "\n",
    "Now we will write a simple function that can be used to split both our training data and our labels into \"folds\", so that we can perform the cross-validation process described above.\n",
    "\n",
    "Write a function that takes in an $n$-dimensional array (where $n > 0$), the desired number of folds $f$, and returns a list containing $f$ **equal-sized** folds. This means that some elements of the array might be excluded from the folds. Each fold should be created by slicing the array along axis-0. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "```python\n",
    ">>> x = np.array([1, 2, 3, 4, 5, 6])\n",
    "\n",
    ">>> make_folds(x, num_folds=1)\n",
    "[array([1, 2, 3, 4, 5, 6])]\n",
    "\n",
    ">>> make_folds(x, num_folds=2)\n",
    "[array([1, 2, 3]), array([4, 5, 6])]\n",
    "\n",
    ">>> make_folds(x, num_folds=3)\n",
    "[array([1, 2]), array([3, 4]), array([5, 6])]\n",
    "\n",
    ">>> make_folds(x, num_folds=4)\n",
    "[array([1]), array([2]), array([3]), array([4])]\n",
    "\n",
    ">>> y = array([[ 0,  1],\n",
    "...            [ 2,  3],\n",
    "...            [ 4,  5],\n",
    "...            [ 6,  7],\n",
    "...            [ 8,  9],\n",
    "...            [10, 11]])\n",
    "\n",
    ">>> make_folds(y, 2)\n",
    "[array([[0, 1],\n",
    "        [2, 3],\n",
    "        [4, 5]]), \n",
    " array([[ 6,  7],\n",
    "        [ 8,  9],\n",
    "        [10, 11]])]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folds(x, num_folds):\n",
    "    \"\"\" Divides the array `x` along axis-0 into a list of equal-sized \n",
    "    sub-arrays.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy.ndarray, shape=(N, ...)\n",
    "        An array of one or more dimensions, to be split along axis-0\n",
    "    \n",
    "    num_folds : int \n",
    "        The number of equal-sized folds to split `x` into. \n",
    "        Assume that: 0 < num_folds <= N.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List[numpy.ndarray]\n",
    "        A list of the sub-divided arrays\"\"\"\n",
    "    # student code goes here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bwsi_grader.cogworks.nearest_neighbors import grade_make_folds\n",
    "grade_make_folds(make_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will the lists `x_train_folds` and `y_train_folds`.\n",
    "\n",
    "`x_train_folds` is a list that should store consecutive slices\n",
    "of the training data, creating equal-sized grouping of images. \n",
    "I.e. `x_train_folds[0]` should return the\n",
    "array corresponding to fold-0 of the data.\n",
    "\n",
    "`y_train_folds` is a list that should store the corresponding labels for each fold.\n",
    "I.e. `y_train_folds[0]` should return an array containing the labels\n",
    "for fold-0 of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute this cell\n",
    "\n",
    "# we will be using 5 fold in our cross-validation\n",
    "num_folds = 5\n",
    "x_train_folds = make_folds(x_train, num_folds=num_folds)\n",
    "y_train_folds = make_folds(y_train, num_folds=num_folds)\n",
    "\n",
    "# we want to evaluate our classifier's accuracy\n",
    "# for the following values of k\n",
    "k_values = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now perform cross-validation analysis to find an ideal k-value for your classifier.\n",
    "\n",
    " For each k-value, measure the n-accuracies of the classifier,\n",
    " one for each validation fold, and save the \n",
    " k -> [acc_1, acc_2, ..., acc_n] mapping in the `accuracies`\n",
    " dictionary.\n",
    "\n",
    "Use `compute_distances` to produce the MxN distances between\n",
    "the the M \"unlabeled\" images and the N \"labeled\" images.\n",
    "Feed this array of distances, the N labels, and k into\n",
    "`predict` to produce (M,) predicted labels for the \"unlabeled\"\n",
    "images\n",
    "\n",
    "Compare the M predicted labels against the M true labels\n",
    "and measure the accuracy of the classifier: num_correct / M\n",
    "\n",
    "For each time you hold out one of your n folds for validation,\n",
    " you will need to form a single array out of your n-1 folds\n",
    " of training (labeled) data, holding out whichever fold is being used as the validation (unlabeled) data. Similarly, you will need to form a single array of the corresponding labels of the $n-1$ training folds. `numpy.concatenate` will be valuable here. Look up its documentation.\n",
    " \n",
    "This process needs to be performed every time you hold out a different validation fold. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# cross-validation pseudo-code\n",
    "for fold_i in range(num_folds):\n",
    "    validation_data = fold_i-array selected from list-of-folds; \n",
    "                      shape-(M, D) array\n",
    "    labeled_data = the other folds \"stacked together\" as one array; \n",
    "                   shape-(N, D) array\n",
    "    validation_labels = labels for fold-i; shape-(M,) array\n",
    "    labels = labels for remaining data; shape-(N,) array\n",
    "\n",
    "    for k in k_values:\n",
    "        - Predict the M-labels for the validation fold, using \n",
    "          k-nearest neighbors with the shape-(N, D) labeled_data.\n",
    "            -- You will need to compute the distance between the pairs \n",
    "               of validation-data and labeled-data.\n",
    "        - Compute the classification accuracy by comparing against the \n",
    "          actual labels for the validation data.\n",
    "                   \n",
    "        - The dictionary `accuracies` should store a list in \n",
    "          association with each k value. k -> list_of_accuracies\n",
    "          -- Append this accuracy to the list associated with this \n",
    "             k value.\n",
    "             \n",
    "accuracy =  (number of correctly assigned labels) \n",
    "           ----------------------------------------\n",
    "           (total number of labels assigned; i.e. M)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracies is a dictionary that must map the k-value\n",
    "# to the resulting list of n classifier accuracies, one\n",
    "# accuracy for each validation fold.\n",
    "accuracies = {}  # maps k -> [acc_1, acc_2, ..., acc_n]\n",
    "\n",
    "\n",
    "## STUDENT CROSS VALIDATION CODE GOES HERE ##\n",
    "# execute this cell once completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute this cell\n",
    "# this will check if you recorded the appropriate\n",
    "# number of fold-accuracies, for each k-value\n",
    "assert sorted(accuracies) == k_values\n",
    "for list_of_acc in accuracies.values():\n",
    "    assert len(list_of_acc) == num_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute this cell to plot the n accuracies, for each k-value, along\n",
    "# with the average accuracy.\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for k in k_values:\n",
    "    ax.scatter([k] * len(accuracies[k]), accuracies[k], marker=\"x\")\n",
    "\n",
    "# plot the trend line with error bars that correspond to standard deviation\n",
    "accuracies_mean = np.array([np.mean(v) for k,v in sorted(accuracies.items())])\n",
    "accuracies_std = np.array([np.std(v) for k,v in sorted(accuracies.items())])\n",
    "ax.errorbar(k_values, accuracies_mean, yerr=accuracies_std, label=\"mean accuracy\")\n",
    "ax.set_title('Cross-validation on k')\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('Cross-validation accuracy')\n",
    "ax.grid(True)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the buttons at the bottom-left portion of the image to zoom in on parts of the plot. When hovering your cursor over the plot, the (x,y) coordinate of the cursor will be displayed at the bottom-right portion of the plot. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your recorded accuracies to answer Question 4a and 4b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4 STUDENT CODE GOES HERE\n",
    "all_acc = list()\n",
    "for k in accuracies:\n",
    "    all_acc.extend(accuracies[k])\n",
    "print(max(all_acc))\n",
    "print(min(all_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the optimal value for $k$ (the k-value with the best mean accuracy), evaluate the nearest neighbor classifier on the test-data (as the unlabeled data) and the training data (as the labeled data), and record its accuracy. You will be asked to report this \"test accuracy\" to three decimal places in Question 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5 STUDENT CODE GOES HERE\n",
    "k = 10\n",
    "dists = compute_distances(x_test, x_train)\n",
    "labels = predict(dists, y_train, k)\n",
    "acc = np.mean(labels == y_test)\n",
    "round(float(acc), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this test accuracy compare to the mean validation accuracy? Did the cross-validation process lead us to find a k-value such that our classifier performed \"as expected\" on data that it had never encountered before? Although you will not be asked to submit an answer for these questions, it is important that you are able to answer them clearly. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
